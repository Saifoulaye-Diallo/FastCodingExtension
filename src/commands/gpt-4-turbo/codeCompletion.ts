import * as vscode from 'vscode';
import { openai } from '../../llms/openaiClient.ts';
import { callHuggingFaceModelFIM } from '../../llms/huggingfaceClient';
import { getConfigurationModel } from '../../utils/settings';

/**
 * G√©n√®re une compl√©tion IA pour du code √† partir du contexte autour du curseur,
 * en choisissant dynamiquement le mod√®le LLM selon les pr√©f√©rences utilisateur.
 * @param before - Code avant le curseur
 * @param after - Code apr√®s le curseur (optionnel)
 * @returns Suggestion de code √† ins√©rer
 */
export async function codeCompletion(before: string, after: string = ''): Promise<string> {
  const prompt = `${before}<CURSOR>${after}`;
  const model = getConfigurationModel();

  try {
   switch (model) {
  case 'StarCoder': {
    const prefix = "def say_hello():\n    ";
    const suffix = "\n    print('done')";
    const generated = await callHuggingFaceModelFIM(prefix, suffix);


    console.log("[FastCoding] ü§ñ Mod√®le s√©lectionn√© : StarCoder");
    vscode.window.showInformationMessage("üí° Mod√®le IA utilis√© : StarCoder (Hugging Face)");
    
    return generated;
  }

  case 'CodeLlama': {
    console.warn("[FastCoding] ‚ö†Ô∏è CodeLlama non disponible avec cette cl√© Hugging Face.");
    vscode.window.showWarningMessage("üö´ Le mod√®le CodeLlama n'est pas encore accessible avec votre cl√© Hugging Face.");
    
    return '';
  }

  case 'GPT-4':
  default: {
    console.log("[FastCoding] ü§ñ Mod√®le s√©lectionn√© : GPT-4");
    vscode.window.showInformationMessage("üí° Mod√®le IA utilis√© : GPT-4 Turbo");

    const completion = await openai.chat.completions.create({
      model: "gpt-4-turbo",
      messages: [
        {
          role: "system",
          content: `Tu es une IA de compl√©tion de code comme GitHub Copilot.

Ton r√¥le est de pr√©dire ce que l‚Äôutilisateur est en train de taper, √† partir du contexte fourni.

‚ùó R√®gles strictes :
- Ne retourne que du **code brut** (aucun commentaire, explication ou markdown).
- Le code doit √™tre pr√™t √† √™tre ins√©r√© imm√©diatement apr√®s le curseur.
- Chaque ligne de code doit √™tre correctement indent√©e.
- Si plusieurs instructions sont g√©n√©r√©es, elles doivent √™tre s√©par√©es par des retours √† la ligne (\\n).
- Le code g√©n√©r√© ne doit pas causer d'erreurs de syntaxe.
- Aucune phrase, aucun texte explicatif ou d√©coratif.`
        },
        {
          role: "user",
          content: prompt
        }
      ],
      max_tokens: 80,
      temperature: 0.1,
      top_p: 1,
      stop: ["\n\n"]
    });

    return completion.choices[0]?.message?.content?.trim() ?? '';
  }
}
  } catch (error) {
    console.error('[FastCoding] ‚ùå Erreur LLM inline :', error);
    return '';
  }
}
